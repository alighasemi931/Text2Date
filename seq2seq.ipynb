{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9251, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"date.csv\").drop_duplicates(subset = \"informal_date\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Normalize and split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>informal_date</th>\n",
       "      <th>formal_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;start&gt; پنجم اردیبهشت 1402 &lt;ends&gt;</td>\n",
       "      <td>&lt;start&gt; 1402/02/05 &lt;ends&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;start&gt; 17 آبان 1395 &lt;ends&gt;</td>\n",
       "      <td>&lt;start&gt; 1395/08/17 &lt;ends&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;start&gt; 1 1403 مهر &lt;ends&gt;</td>\n",
       "      <td>&lt;start&gt; 1403/07/01 &lt;ends&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;start&gt; سال مهر اول 1403 &lt;ends&gt;</td>\n",
       "      <td>&lt;start&gt; 1403/07/01 &lt;ends&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;start&gt; 1403-07-01 &lt;ends&gt;</td>\n",
       "      <td>&lt;start&gt; 1403/07/01 &lt;ends&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29435</th>\n",
       "      <td>&lt;start&gt; پانزدهم آبان 1307 &lt;ends&gt;</td>\n",
       "      <td>&lt;start&gt; 1307/08/15 &lt;ends&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29436</th>\n",
       "      <td>&lt;start&gt; هجدهم آذر 1306 &lt;ends&gt;</td>\n",
       "      <td>&lt;start&gt; 1306/09/18 &lt;ends&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29437</th>\n",
       "      <td>&lt;start&gt; بیست و دوم دی 1305 &lt;ends&gt;</td>\n",
       "      <td>&lt;start&gt; 1305/10/22 &lt;ends&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29439</th>\n",
       "      <td>&lt;start&gt; پنجم اسفند 1303 &lt;ends&gt;</td>\n",
       "      <td>&lt;start&gt; 1303/12/05 &lt;ends&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29441</th>\n",
       "      <td>&lt;start&gt; سی و یکم اردیبهشت 1301 &lt;ends&gt;</td>\n",
       "      <td>&lt;start&gt; 1301/02/31 &lt;ends&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9251 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               informal_date                formal_date\n",
       "0          <start> پنجم اردیبهشت 1402 <ends>  <start> 1402/02/05 <ends>\n",
       "1                <start> 17 آبان 1395 <ends>  <start> 1395/08/17 <ends>\n",
       "2                  <start> 1 1403 مهر <ends>  <start> 1403/07/01 <ends>\n",
       "3            <start> سال مهر اول 1403 <ends>  <start> 1403/07/01 <ends>\n",
       "4                  <start> 1403-07-01 <ends>  <start> 1403/07/01 <ends>\n",
       "...                                      ...                        ...\n",
       "29435       <start> پانزدهم آبان 1307 <ends>  <start> 1307/08/15 <ends>\n",
       "29436          <start> هجدهم آذر 1306 <ends>  <start> 1306/09/18 <ends>\n",
       "29437      <start> بیست و دوم دی 1305 <ends>  <start> 1305/10/22 <ends>\n",
       "29439         <start> پنجم اسفند 1303 <ends>  <start> 1303/12/05 <ends>\n",
       "29441  <start> سی و یکم اردیبهشت 1301 <ends>  <start> 1301/02/31 <ends>\n",
       "\n",
       "[9251 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def normalize_text(text):\n",
    "    # Convert Persian numbers to Latin\n",
    "    persian_to_latin = {\n",
    "        '۰': '0', '۱': '1', '۲': '2', '۳': '3', '۴': '4',\n",
    "        '۵': '5', '۶': '6', '۷': '7', '۸': '8', '۹': '9'\n",
    "    }\n",
    "    for persian, latin in persian_to_latin.items():\n",
    "        text = text.replace(persian, latin)\n",
    "    \n",
    "    # Normalize Persian characters\n",
    "    text = text.replace('ي', 'ی').replace('ك', 'ک')\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text.strip())\n",
    "    text = f\"<start> {text} <ends>\"\n",
    "    return text\n",
    "\n",
    "df['formal_date'] = df['formal_date'].apply(normalize_text)\n",
    "df['informal_date'] = df['informal_date'].apply(normalize_text)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val , test = train_test_split(df , test_size=0.1 , random_state= 42)\n",
    "train ,val = train_test_split(train_val,test_size=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 7492\n",
      "Validation samples: 833\n",
      "Test samples: 926\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training samples: {len(train)}\")\n",
    "print(f\"Validation samples: {len(val)}\")\n",
    "print(f\"Test samples: {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            input_seq, target_seq = batch\n",
    "            input_seq, target_seq = input_seq.to(device), target_seq.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(input_seq)\n",
    "            loss = criterion(output.view(-1, output.size(-1)), target_seq.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_seq, target_seq = batch\n",
    "                input_seq, target_seq = input_seq.to(device), target_seq.to(device)\n",
    "                output = model(input_seq)\n",
    "                loss = criterion(output.view(-1, output.size(-1)), target_seq.view(-1))\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(\"Model saved!\")\n",
    "\n",
    "# Assuming you have your data prepared and model defined\n",
    "model = YourTransformerModel()  # Define your model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_token_id)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Prepare your data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "num_epochs = 10\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
